{
 "cells": [
  {
   "cell_type": "code",
   "id": "2907945b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-12-16T18:09:38.402337Z",
     "start_time": "2024-12-16T18:09:38.364437Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Evaluate Coder PR\n",
    "Calculate precision and recall for NYSIIS, Soundex, etc. code\n",
    "\n",
    "## Tiny Query\n",
    "\n",
    "| Experiment | Threshold     | Precision | Recall | F1     | F2     |\n",
    "|------------|---------------|-----------|--------|--------|--------|\n",
    "|Soundex     |               | 0.142     | 0.522  | 0.22   | 0.34   |\n",
    "|Nysiis      |               | 0.147     | 0.358  | 0.20   | 0.28   |\n",
    "|Nama        | 0.10 @40      | 0.148     | 0.586  | 0.24   | 0.37   |"
   ],
   "id": "c68ef0ba9ecd2faa"
  },
  {
   "cell_type": "code",
   "id": "8d131857",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-12-16T18:25:20.930930Z",
     "start_time": "2024-12-16T18:25:20.874881Z"
    }
   },
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import boto3\n",
    "import jellyfish\n",
    "from mpire import WorkerPool\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from py4j.java_gateway import JavaGateway\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nama.data.filesystem import download_file_from_s3\n",
    "from nama.data.utils import read_csv\n",
    "from nama.eval.freq_metrics import calc_avg_precision_recall\n",
    "from nama.models.tokenizer import get_tokenize_function_and_vocab\n",
    "from nama.models.utils import top_similar_names\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "b54bdec3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-12-16T18:28:18.292270Z",
     "start_time": "2024-12-16T18:28:18.196Z"
    }
   },
   "source": [
    "# config\n",
    "# TODO run both given and surname\n",
    "given_surname = \"given\"\n",
    "# given_surname = \"surname\"\n",
    "\n",
    "nama_threshold = 0.1\n",
    "nama_limit = 40\n",
    "\n",
    "linkage = \"average\"  # average, complete\n",
    "similarity_threshold = 0.1 if given_surname == \"given\" else 0.25\n",
    "cluster_freq_normalizer = \"none\"  # log, log10, none\n",
    "max_tokens = 10\n",
    "bi_encoder_vocab_size = 2048\n",
    "num_epochs = 8\n",
    "embedding_dim = 256\n",
    "learning_rate = 0.00005 \n",
    "\n",
    "clusters_path = f\"s3://fs-nama-data/2024/nama-data/data/processed/clusters_{given_surname}-{linkage}-{similarity_threshold}-{cluster_freq_normalizer}-augmented.json\"\n",
    "super_clusters_path = f\"s3://fs-nama-data/2024/nama-data/data/processed/super_clusters_{given_surname}-{linkage}-{similarity_threshold}-{cluster_freq_normalizer}.json\"\n",
    "tokenizer_path=f\"s3://fs-nama-data/2024/nama-data/data/models/fs-{given_surname}-subword-tokenizer-{bi_encoder_vocab_size}.json\"\n",
    "bi_encoder_path = f\"s3://fs-nama-data/2024/nama-data/data/models/bi_encoder-ce-{given_surname}-{num_epochs}-{embedding_dim}-{num_epochs}-{bi_encoder_vocab_size}-{learning_rate}.pth\"\n",
    "\n",
    "train_path = f\"s3://fs-nama-data/2024/familysearch-names/processed/tree-hr-{given_surname}-train.csv.gz\"\n",
    "test_path = f\"s3://fs-nama-data/2024/familysearch-names/processed/tree-hr-{given_surname}-test.csv.gz\"\n",
    "query_path = f\"s3://fs-nama-data/2023/familysearch-names/processed/query-names-{given_surname}-v2.csv.gz\"\n",
    "pref_path = f\"s3://fs-nama-data/2024/familysearch-names/processed/tree-preferred-{given_surname}-aggr.csv.gz\"\n",
    "nickname_path = \"../references/givenname_nicknames.csv\""
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "4190d2c0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "id": "2f5157ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T18:23:52.819411Z",
     "start_time": "2024-12-16T18:23:52.758897Z"
    }
   },
   "source": [
    "# these nicknames include nickname heads going to themselves (e.g., john -> john)\n",
    "nicknames = defaultdict(set)\n",
    "if given_surname == \"given\":\n",
    "    with open(nickname_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            names = line.split(',')\n",
    "            headname = names[0]\n",
    "            for name in names:\n",
    "                nicknames[name].add(headname)\n",
    "print(len(nicknames))\n",
    "print(nicknames['zachary'])\n",
    "print(nicknames['zachariah'])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1201\n",
      "{'zachariah'}\n",
      "{'zachariah'}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "5b215bc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T18:26:13.539557Z",
     "start_time": "2024-12-16T18:26:08.010821Z"
    }
   },
   "source": [
    "path = download_file_from_s3(query_path) if query_path.startswith(\"s3://\") else query_path\n",
    "query_names = read_csv(path)[\"name\"].tolist()\n",
    "print(len(query_names))\n",
    "query_names[0:3]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['james', 'janos', 'caroline']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "cec1c31c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T18:27:06.732968Z",
     "start_time": "2024-12-16T18:26:13.542832Z"
    }
   },
   "source": [
    "# load pref names\n",
    "path = download_file_from_s3(pref_path) if pref_path.startswith(\"s3://\") else pref_path\n",
    "pref_df = read_csv(path)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "5dd7b1fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T18:27:11.687460Z",
     "start_time": "2024-12-16T18:27:06.735607Z"
    }
   },
   "source": [
    "# create common names pref names that occur >= common_name_threshold\n",
    "common_names = [name for name, freq in zip(pref_df['name'], pref_df['frequency']) \\\n",
    "                if len(name) > 1 and re.fullmatch(r'[a-z]+', name)]\n",
    "common_names = common_names[:10000]\n",
    "len(common_names)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "74186497",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T18:27:15.844422Z",
     "start_time": "2024-12-16T18:27:11.688714Z"
    }
   },
   "source": [
    "path = download_file_from_s3(train_path) if train_path.startswith(\"s3://\") else train_path\n",
    "train_df = read_csv(path)\n",
    "print(train_df.shape)\n",
    "train_df.head(3)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3580532, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  tree_name record_name  frequency\n",
       "0         a           a    1622927\n",
       "1        aa           a        139\n",
       "2        aa          aa         45"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree_name</th>\n",
       "      <th>record_name</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>1622927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa</td>\n",
       "      <td>a</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aa</td>\n",
       "      <td>aa</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "36b52952",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T18:27:21.905737Z",
     "start_time": "2024-12-16T18:27:19.356558Z"
    }
   },
   "source": [
    "path = download_file_from_s3(test_path) if test_path.startswith(\"s3://\") else test_path\n",
    "test_df = pd.read_csv(path, na_filter=False)\n",
    "print(test_df.shape)\n",
    "test_df.head(3)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1195039, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   tree_name record_name  frequency\n",
       "0     aaaard     aagaard         12\n",
       "1     aaagot       aagot          8\n",
       "2  aaassiena    aassiena          2"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree_name</th>\n",
       "      <th>record_name</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaaard</td>\n",
       "      <td>aagaard</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaagot</td>\n",
       "      <td>aagot</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaassiena</td>\n",
       "      <td>aassiena</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "19e5c067",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T18:27:22.853367Z",
     "start_time": "2024-12-16T18:27:22.389738Z"
    }
   },
   "source": [
    "all_df = pd.concat([train_df, test_df])\n",
    "print(all_df.shape)\n",
    "all_df.head(3)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4775571, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  tree_name record_name  frequency\n",
       "0         a           a    1622927\n",
       "1        aa           a        139\n",
       "2        aa          aa         45"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree_name</th>\n",
       "      <th>record_name</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>1622927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa</td>\n",
       "      <td>a</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aa</td>\n",
       "      <td>aa</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "5f7ae378",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T18:29:22.320908Z",
     "start_time": "2024-12-16T18:28:54.894255Z"
    }
   },
   "source": [
    "nama_name_cluster = {}       # name -> cluster position\n",
    "nama_cluster_centroids = []  # centroid for each cluster\n",
    "nama_cluster_labels = []     # label for each cluster\n",
    "nama_cluster_super_cluster = {}  # cluster label -> super_cluster label\n",
    "\n",
    "path = download_file_from_s3(clusters_path) if clusters_path.startswith(\"s3://\") else clusters_path\n",
    "with open(path, 'r') as f:\n",
    "    nama_clusters = json.load(f)  # cluster label -> names, centroid\n",
    "\n",
    "path = download_file_from_s3(super_clusters_path) if super_clusters_path.startswith(\"s3://\") else super_clusters_path\n",
    "with open(path, 'r') as f:\n",
    "    nama_super_clusters = json.load(f)  # super_cluster label -> cluster labels\n",
    "\n",
    "for label, cluster in nama_clusters.items():\n",
    "    for name in cluster['names']:\n",
    "        nama_name_cluster[name] = len(nama_cluster_labels)\n",
    "    nama_cluster_labels.append(label)\n",
    "    nama_cluster_centroids.append(np.array(cluster['centroid']))\n",
    "nama_cluster_labels = np.array(nama_cluster_labels)\n",
    "\n",
    "for super_cluster_label, super_cluster in nama_super_clusters.items():\n",
    "    for cluster_label in super_cluster:\n",
    "        nama_cluster_super_cluster[cluster_label] = super_cluster_label"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "00eb0732",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T23:28:21.239508Z",
     "start_time": "2024-12-16T23:28:21.071496Z"
    }
   },
   "source": [
    "len(nama_name_cluster)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154032"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "319d51b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T23:30:41.500211Z",
     "start_time": "2024-12-16T23:30:37.053145Z"
    }
   },
   "source": [
    "names = set(all_df[\"tree_name\"]) | set(all_df[\"record_name\"])\n",
    "cnt = 0\n",
    "for ix, name in enumerate(names):\n",
    "    if name not in nama_name_cluster:\n",
    "        cnt += 1\n",
    "print(len(names), cnt, cnt/len(names))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1897758 1751954 0.9231703936961404\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "e59809cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T23:30:45.896455Z",
     "start_time": "2024-12-16T23:30:41.502627Z"
    }
   },
   "source": [
    "total_freq = 0\n",
    "cluster_freq = 0\n",
    "for name, freq in zip(all_df['tree_name'], all_df['frequency']):\n",
    "    total_freq += freq\n",
    "    if name in nama_name_cluster:\n",
    "        cluster_freq += freq\n",
    "print(total_freq, cluster_freq, cluster_freq/total_freq)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076069127 1054256502 0.9797293459567863\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "508f5162",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T23:30:50.260088Z",
     "start_time": "2024-12-16T23:30:45.897929Z"
    }
   },
   "source": [
    "total_freq = 0\n",
    "cluster_freq = 0\n",
    "for name, freq in zip(all_df['record_name'], all_df['frequency']):\n",
    "    total_freq += freq\n",
    "    if name in nama_name_cluster:\n",
    "        cluster_freq += freq\n",
    "print(total_freq, cluster_freq, cluster_freq/total_freq)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076069127 1046111160 0.9721598118110492\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "914e470f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T23:31:06.047231Z",
     "start_time": "2024-12-16T23:30:50.262725Z"
    }
   },
   "source": [
    "# load tokenizer\n",
    "path = download_file_from_s3(tokenizer_path) if tokenizer_path.startswith(\"s3://\") else tokenizer_path\n",
    "tokenize, tokenizer_vocab = get_tokenize_function_and_vocab(tokenizer_path=path, max_tokens=max_tokens)\n",
    "len(tokenizer_vocab)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "c1a6efea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T23:31:27.282874Z",
     "start_time": "2024-12-16T23:31:06.049093Z"
    }
   },
   "source": [
    "# load bi-encoder\n",
    "path = download_file_from_s3(bi_encoder_path) if bi_encoder_path.startswith(\"s3://\") else bi_encoder_path\n",
    "bi_encoder_model = torch.load(path)\n",
    "bi_encoder_model.eval()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_150454/2291865325.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bi_encoder_model = torch.load(path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BiEncoder(\n",
       "  (embedding): Embedding(2048, 256)\n",
       "  (positional_embedding): Embedding(10, 256)\n",
       "  (pooling): AdaptiveAvgPool1d(output_size=1)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "4d3d1200",
   "metadata": {},
   "source": [
    "## Set up FamilySearch coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaa04f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# match-spark/pipeline mexico-dup-classifier branch\n",
    "# java -cp target/spark-pipeline.jar org.familysearch.search.spark.py4j.Py4JGateway\n",
    "\n",
    "gateway = JavaGateway()\n",
    "\n",
    "def fs_coder(name):\n",
    "    # can result ever contain multiple comma-separated codes?\n",
    "    # if so, do we index both and query one, or index one and query both?\n",
    "    return gateway.getClusters(name, given_surname == 'surname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6f96c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_coder('ebbie')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e9425f-3310-4cea-9cde-411917fefb32",
   "metadata": {},
   "source": [
    "## Set up FS Nama coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70ef4f3e-ec15-48a7-8311-9ba8dd92a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# searchng-standards-wrapper py4j branch\n",
    "# java -classpath target/searchng-standards-wrapper.jar org.familysearch.recordsearch.standards.Py4JGateway\n",
    "\n",
    "gateway = JavaGateway()\n",
    "\n",
    "def fs_nama_coder(name):\n",
    "    return gateway.getClusters(name, given_surname == 'surname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a20fab0-8722-4b98-adaa-7e3dec7e133a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abbey/eby'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_nama_coder('ebbie')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bf761e",
   "metadata": {},
   "source": [
    "## Set up nama coder"
   ]
  },
  {
   "cell_type": "code",
   "id": "02eb0943",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T23:29:21.697651Z",
     "start_time": "2024-12-16T23:29:21.645805Z"
    }
   },
   "source": [
    "def get_embedding(name):\n",
    "    embedding = bi_encoder_model.get_embedding(tokenize(name)) \n",
    "    embedding /= np.linalg.norm(embedding)\n",
    "    return embedding"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "80c4161a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T23:29:42.716834Z",
     "start_time": "2024-12-16T23:29:42.669837Z"
    }
   },
   "source": [
    "def nama_coder_threshold_limit(name, threshold, limit):\n",
    "    codes = []\n",
    "        \n",
    "    # get the primary (indexed) cluster\n",
    "    if name in nama_name_cluster:\n",
    "        # if it is in the cluster dictionary, get that cluster\n",
    "        cluster_label = nama_cluster_labels[nama_name_cluster[name]]\n",
    "    else:\n",
    "        # if it isn't, get the nearest cluster\n",
    "        emb = get_embedding(name)\n",
    "        cluster_label = top_similar_names(emb, nama_cluster_centroids, nama_cluster_labels, \n",
    "                                          threshold=0, top_n=1)[0][0]\n",
    "    # index it under this cluster\n",
    "    codes.append(cluster_label)\n",
    "    \n",
    "    # include additional clusters in this cluster's super-cluster\n",
    "    super_cluster_clusters = nama_super_clusters.get(nama_cluster_super_cluster.get(cluster_label, None), [])\n",
    "    for nearby_cluster in super_cluster_clusters:\n",
    "        # don't check length, because we want all clusters in the super-cluster\n",
    "        if nearby_cluster not in codes:\n",
    "            codes.append(nearby_cluster)\n",
    "\n",
    "    # include additional clusters near this cluster\n",
    "    if limit > len(codes):\n",
    "        emb = get_embedding(name)\n",
    "        nearby_clusters, similarities = top_similar_names(emb, nama_cluster_centroids, nama_cluster_labels,\n",
    "                                                          threshold=threshold, top_n=limit-len(codes))\n",
    "        for nearby_cluster, similarity in zip(nearby_clusters, similarities):\n",
    "            # print(name, nearby_cluster, similarity)\n",
    "            if len(codes) >= limit or similarity < threshold:\n",
    "                break\n",
    "            if nearby_cluster not in codes:\n",
    "                codes.append(nearby_cluster)\n",
    "            \n",
    "    return ','.join(codes)\n",
    "\n",
    "def nama_coder(name):\n",
    "    return nama_coder_threshold_limit(name, nama_threshold, nama_limit)"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "25541951",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T23:31:43.129629Z",
     "start_time": "2024-12-16T23:31:39.272655Z"
    }
   },
   "source": [
    "def _sample(code):\n",
    "    return ' '.join(nama_clusters[code]['names'][:8])\n",
    "\n",
    "total_codes = 0\n",
    "for name in ['dallan', 'richard', 'solveig', 'evelyn', 'barbara', 'susan', 'henry', 'becca']:\n",
    "    codes = nama_coder_threshold_limit(name, threshold=0.65, limit=40)\n",
    "    codes = codes.split(',')\n",
    "    print(name, len(codes))\n",
    "    total_codes += len(codes)\n",
    "    for code in codes:\n",
    "        print('   ', code, _sample(code))\n",
    "print(total_codes)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dallan 4\n",
      "    dillon/dillon dillan dalen dillion dillin dillian dellujan dallan dallin\n",
      "    dillon/dylan diran dyann dilan dylan\n",
      "    dallas/dallas dallas dalis dalay dallace dalles dallice dalyce dalit\n",
      "    dolan/dolan dolling dolen doljin dalling dolon dollin dollen dolena\n",
      "richard 17\n",
      "    richard/richard richards richaurd richerd ritchard richardae recardo riccarda richeard\n",
      "    richard/dack dec deak daek dack dek deck\n",
      "    richard/dick dyck dickie dich diack dickey dick dziecko dika\n",
      "    richard/ricky richelieu rische richert ritchie rickie ricky richa ricki\n",
      "    richard/richardson ricketson richeson richarson rickerson richardson richison richerson richardsen\n",
      "    richard/rd ryd rd\n",
      "    richard/record records record secord recorded recherd\n",
      "    richard/ryszard ryszard buzzard blizard blizzard\n",
      "    richard/dk leduc duc dk\n",
      "    rchd/richdi ruchard rickhard richarad rochard rashid rchd richford rachard\n",
      "    richan/richenda richenda richens richan richins richenza richland\n",
      "    frederick/rychli richo richs richley richy rychli richow\n",
      "    ricd/ricd rycd ricdi ricrd ricd\n",
      "    rachel/richmal richal richum richmal richm richmuth\n",
      "    ricus/ricus richdus dicus richus richdj riches ricus rikus ricdus\n",
      "    richmond/richmond richmond richmundis richman richmodis richmand rickman richmunda richmon\n",
      "    rachel/richildis richilda richildis riquilda rachilde ricalde richilde ricalda richde\n",
      "solveig 3\n",
      "    solveig/solveig solveg solver solberg solvig solvieg solbjorg solveigar solvejg\n",
      "    sylvia/salvia solvei solvej solvie salvy salvia solvia salvie solvey\n",
      "    solo/solie solie solio soloa soll soly soloi soli soliai\n",
      "evelyn 9\n",
      "    evelyn/evelyn evelyen evolyn evlin evelina evelyne eveyln avelyn evalyn\n",
      "    evalena/evalina evalyne evalina everlene evoline evylene evalean evyleen evalene\n",
      "    eviline/evylin evilina evline eviline evyline evlina evellina evilin evylin\n",
      "    evelia/evelia evil evella evely evila evla evelio evilla evelie\n",
      "    evinda/evinda evelinda eventa evenia evinda evalinda evena\n",
      "    evan/evan evany evans evina evonna evant evann euan evanir\n",
      "    evi/evy evi evy evvie eui eevi evey eavy evee\n",
      "    everly/everline everleigh everly everleen eversole evelee everlee everlena eversley\n",
      "    evan/even even eivind evzen event efven evin eivend\n",
      "barbara 15\n",
      "    barbara/barbara berber barbrue barbey barrabra barberye barbar barbarita barebro\n",
      "    barbara/beb beb beiba bieber\n",
      "    barbara/barbetta babit barbetta babete barbette babeth babethe barbet babett\n",
      "    barbara/barra bapa baa bawa baia bavara baua barva barra\n",
      "    barbara/barbli babbie babie barbi babina babli babba babby baebi\n",
      "    barbara/baber brabra babar babre babrara babora babra babry baber\n",
      "    barbara/vare vare varvar vave\n",
      "    barbara/berbgen berbgen\n",
      "    barbara/warwara warsaw warwara fujiwara\n",
      "    barbara/burb burb berb\n",
      "    barbara/barbeli barbelle barbil barble barbele barblin barbol barbl barbalho\n",
      "    barbara/borbala borbalatol borballa borbal borbaranak borbora borbarat borbola borbaly\n",
      "    barrera/barrera baruara barera barrameda barcena barea barrena barrey barrera\n",
      "    barabas/barabas barabas jarbas borbas barhabas barbas\n",
      "    barbel/barbel berbel barbel borbely barbelin barbeline\n",
      "susan 29\n",
      "    susan/susanna susaa suanah sushana susenne susanner susannanak susannak susanha\n",
      "    susan/sanna sanne zsanna sewsanna sanna frusanna sisanna sanni\n",
      "    susan/susie sussie sus sussi suzey sussy susy susee sucie\n",
      "    susan/sush surah suh susah susarah sush suah sasah\n",
      "    susan/zsuzsanna suszanna suszanne suzzanne zusannae suzanae zsuzsana suzzane zuzannae\n",
      "    susan/sue sua suhe seu suye sucy suu suey suie\n",
      "    susan/susa desousa soiza desosa suso suisala susa souisa suisa\n",
      "    susan/sison sibson sson sison sissons sasson sayson\n",
      "    susan/suzete suzete sustaita suetta susetta susete suesette\n",
      "    susan/suke suka sucky sukey suca suky sukeji suckey sukezou\n",
      "    susan/suana shuana shawana sasana suana sosana soana shoshanna sjuana\n",
      "    susan/sanneke sanneke sannigje santje\n",
      "    susan/sake saka saske ska sakes sanka sakie seka saku\n",
      "    susan/suchna suchna zuchna\n",
      "    susan/zuzka zus zuska zuzsa zusa zuzka\n",
      "    susan/sioux vieux vaux devaux deveaux deux sioux\n",
      "    susan/sewa sewsan seus sew sewa sewak\n",
      "    susan/sse suise sse\n",
      "    susan/suster shuster suster zuster schuster suester\n",
      "    susan/zue zho zhuang zue zhi zha zhu zhe\n",
      "    susan/zaner zaner zanele\n",
      "    susan/ozanna ozana ocana hozana ozanne ozanna\n",
      "    susan/sosaia socia sovaia sosaia soraira soia soraia\n",
      "    susan/sucinda sucinda delasalceda salceda sauseda sauceda\n",
      "    susan/sookie smoke sookie smokey smoky snookie snooky sooky sookey\n",
      "    susan/shaune shaku shaye shave shaune shae shake\n",
      "    sussman/sussman sassaman sussman susman susmann susskind soesman zusman susima\n",
      "    susumu/susumu suzu suzue souzou sussumu susu susumu\n",
      "    cecilia/susal susatol susanatol susal\n",
      "henry 44\n",
      "    henry/henry henry hanry hurry nry hry honry henryh heny\n",
      "    henry/heintje hincke heintje hennecke hencken heneke heinken henche hencke\n",
      "    henry/henricus henderiks hendry henrinae hendricka henerine henrics heinerica henricsdr\n",
      "    henry/henri henrci hennri henci hanri henari heneli heyni heneri\n",
      "    henry/hendrik hendryck handrich henrick heinderick hendrick henk hydrick heijndrik\n",
      "    henry/endre endre ondr hendri endrikus endri endrikis endrik endrick\n",
      "    henry/harry harre harye herrye harrij harrey herrie harri harray\n",
      "    henry/jetje jettchen jetje settchen\n",
      "    henry/enrico errico enrico enrrico henerico hennrico henrico\n",
      "    henry/henriette henerietta hendreta henetta heneriata hanetta henerett henriethe henriettie\n",
      "    henry/heinrich hendrich hanrich hennricus hienrich heinich henriech henich hendrih\n",
      "    henry/henny hense hernie henje heinze henne hennere herre henie\n",
      "    henry/drika dik drika drik drick drikje drieka\n",
      "    henry/enrique enrica henrriqueta enrigueta enrique enriqueta henriquieta enrrigue enrriguez\n",
      "    henry/henrs hendrs hendersken henderske handerske enners henrs hinders henderse\n",
      "    henry/arrigo abrigo arciniega arrigoni arrigo errigo arriaga dearriaga\n",
      "    henry/hindric hind hindel hindric hindrix\n",
      "    henry/hy hye hyo hy hyeok hyu\n",
      "    henry/heijo keijiro heijo heijiro heijuurou heizou heizo heigo heikurou\n",
      "    henry/hendr hender hendre hendrdr hindr hansdr hinder henrdr haner\n",
      "    henry/hena henrh henao henno henya henah henio henaro hench\n",
      "    henry/heikki keichi heikichi hikohachi teiichi hideichi niichi eich keiichi\n",
      "    henry/yetti yetti yetive\n",
      "    henry/yrinco yrinco\n",
      "    henry/hira hirsz hariah hirch hira hir hiria hirah haria\n",
      "    henry/hens hens hinau hins hino\n",
      "    henry/henmann heineman heinzmann heinemann heinimann henmann heintzmann hentzmann\n",
      "    henry/heady heydt heady\n",
      "    henry/hynek hinekura hinnerk hynek\n",
      "    henry/hetty hitty hetty hittey\n",
      "    henry/jindrich jetrich jindrich\n",
      "    henry/ettle ettabelle ettle etele etuale\n",
      "    henry/hori hori heri hoori\n",
      "    henry/hendrikje hendrikien hendrikkie hindriktjen hinderkijn hinderktje hendrickjen hinderkien hendrickijen\n",
      "    henry/riko riku noriko rikizou riki rikichi riko\n",
      "    henry/jindriska oldriska jindriska bedriska\n",
      "    henry/hch hrch hitch hecht hch\n",
      "    henry/dr dtr dr\n",
      "    henry/heyer heen heyen heyer heaven heien heijen\n",
      "    henry/enzio ensiso enerio enesio encio enezio edezio enzio ensio\n",
      "    henry/heintz hent heitz hantz heintz haintz hintz hentz\n",
      "    henry/haruo haalou haruo haruyo haruno hero haruzou haruye harout\n",
      "    henry/hanrie hawtrey hanrie hanrey\n",
      "    henry/hin hen heijn heinen hin heyn\n",
      "becca 13\n",
      "    rebecca/becky beaks bekkie becki bekky bece beeka beke beckee\n",
      "    rebecca/bake backy baky baikie bako baki backie backe bake\n",
      "    rebecca/rivka reka rivka rivkah repeka reveka ripeka recka ribeka\n",
      "    rebecca/baca bacca bica baca batucan bicca\n",
      "    rebecca/rebecca rebecah rebecky rebackah rebaca robecka rabecca rebec rebeka\n",
      "    rebecca/rabia rabia raba raber rabaca rabie\n",
      "    rebecca/beachy beachy\n",
      "    rebecca/bexey bexey\n",
      "    rebecca/riah rihi riheiji rihee riah rihari bihari rihe\n",
      "    rebecca/vibeche vibe vibar vribe veber vibeche\n",
      "    rebecca/reba rheba rebo rhebe rebe rebah rebbie rebea rebek\n",
      "    rebecca/rechabina rechabina rechab\n",
      "    cuca/cuca cuca coca cuenca\n",
      "134\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "5802942e",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "id": "a8e69117",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T23:32:43.142303Z",
     "start_time": "2024-12-16T23:32:43.103992Z"
    }
   },
   "source": [
    "def get_all_name_codes(coder_name, coder, names):\n",
    "    \n",
    "    def _wrapped_coder(name):\n",
    "        return name, coder(name)\n",
    "    \n",
    "    if coder_name == 'familysearch' or coder_name == 'nama':\n",
    "        results = [_wrapped_coder(name) for name in tqdm(names, mininterval=5.0)]\n",
    "    else:\n",
    "        with WorkerPool() as pool:\n",
    "            results = pool.map(_wrapped_coder, names, progress_bar=True, progress_bar_options={'mininterval': 5.0})\n",
    "    return results"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "7d742bac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T23:32:45.042936Z",
     "start_time": "2024-12-16T23:32:44.998785Z"
    }
   },
   "source": [
    "def get_codes(coder_name, coder, nicknames, names):\n",
    "    # name2codes simulates query: given a name, what codes to lookup\n",
    "    name2codes = defaultdict(set)\n",
    "    # code2names simulates index: given a code, what names are indexed under that code\n",
    "    code2names = defaultdict(set)\n",
    "    # get codes for name - index name under the first code, query name under all codes\n",
    "    for name, codes in get_all_name_codes(coder_name, coder, names):\n",
    "        for ix, code in enumerate(codes.split(',')):\n",
    "            # query code\n",
    "            name2codes[name].add(code)\n",
    "            # add name to code bucket\n",
    "            if ix == 0:\n",
    "                code2names[code].add(name)\n",
    "        if given_surname == \"given\" and name in nicknames:\n",
    "            # query codes for each nickhead of nickname\n",
    "            for nickhead in nicknames[name]:\n",
    "                codes = coder(nickhead)\n",
    "                for code in codes.split(','):\n",
    "                    name2codes[name].add(code)\n",
    "                    # make sure nickhead is added to the code bucket\n",
    "                    code2names[code].add(nickhead)\n",
    "    return name2codes, code2names\n",
    "\n",
    "def eval_clusters(coder_name, coder, nicknames, data_df, query_names):\n",
    "        name2codes, code2names = get_codes(coder_name, coder,\n",
    "                                           # familysearch and nama coders handle nicknames\n",
    "                                           [] if coder_name in ['familysearch', 'nama'] else nicknames,\n",
    "                                           set(data_df[\"tree_name\"]) | set(data_df[\"record_name\"]))\n",
    "        print(\"total names\", len(name2codes))\n",
    "        print(\"total index entries\", sum(len(names) for names in code2names.values()))\n",
    "        print(\"total codes\", len(code2names))\n",
    "        print(\"total queries\", len(query_names))\n",
    "        print(\"total lookups\", sum(len(name2codes[query]) for query in query_names))\n",
    "        precision, recall, f1, f2 = calc_avg_precision_recall(query_names, \n",
    "                                                                       name2codes, \n",
    "                                                                       code2names, \n",
    "                                                                       data_df)\n",
    "        with open('results.txt', 'w') as f:\n",
    "            f.write(f\"precision={precision}, recall={recall} f1={f1} f2={f2}\\n\")\n",
    "        print(f\"precision={precision}, recall={recall} f1={f1} f2={f2}\")"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "89e5baf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T23:32:53.807979Z",
     "start_time": "2024-12-16T23:32:53.443291Z"
    }
   },
   "source": [
    "tiny_df = all_df.sample(n=100_000, random_state=42)\n",
    "len(tiny_df)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "47ca59ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T02:07:45.188079Z",
     "start_time": "2024-12-16T23:34:03.397148Z"
    }
   },
   "source": [
    "nama_threshold = 0.75\n",
    "nama_limit = 0\n",
    "\n",
    "coders = [\n",
    "    ('soundex', jellyfish.soundex), \n",
    "    ('nysiis', jellyfish.nysiis), \n",
    "    ('nama', nama_coder),\n",
    "#     ('familysearch', fs_coder),\n",
    "#     ('fs-nama', fs_nama_coder),    \n",
    "    ]\n",
    "data_sources = [\n",
    "    ('tiny', tiny_df),\n",
    "#     ('train', train_df),\n",
    "#     ('test', test_df),\n",
    "#     ('all', all_df),\n",
    "    ]\n",
    "for label, data_df in data_sources:\n",
    "    print(label)\n",
    "    for coder_name, coder in coders:\n",
    "        print(coder_name)\n",
    "        eval_clusters(coder_name, coder, nicknames, data_df, query_names)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiny\n",
      "soundex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125464/125464 [00:01<00:00, 73316.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total names 125464\n",
      "total index entries 125482\n",
      "total codes 4834\n",
      "total queries 5000\n",
      "total lookups 6220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [02:41<00:00, 31.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=0.1421674428294558, recall=0.5217846354629473 f1=0.22345223324626126 f2=0.3401370422742517\n",
      "nysiis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 125464/125464 [00:01<00:00, 77673.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total names 125464\n",
      "total index entries 125482\n",
      "total codes 37257\n",
      "total queries 5000\n",
      "total lookups 6506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [02:48<00:00, 29.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=0.14733403965154154, recall=0.3583130964271831 f1=0.20880852353309892 f2=0.27854037596859293\n",
      "nama\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125464/125464 [2:25:34<00:00, 14.36it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total names 125464\n",
      "total index entries 125464\n",
      "total codes 15019\n",
      "total queries 5000\n",
      "total lookups 82091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [02:28<00:00, 33.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=0.14783639884435323, recall=0.5862144545660852 f1=0.2361248774820221 f2=0.367980528541687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83b756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
